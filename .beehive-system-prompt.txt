================================================================================
PLAN CONTEXT - Your task is part of an ordered plan:
================================================================================

Plan: Scaffold the ml_experiments framework from scratch. This is an empty repo that needs full project setup. Create: (1) pyproject.toml with all dependencies (torch, diffusers, transformers, accelerate, modal, webdataset, boto3, pydantic, rich, bitsandbytes, torchmetrics), (2) core/experiment.py base Experiment class with config loading, metric logging, and checkpointing, (3) core/modal_runner.py with Modal app definition including a CUDA+PyTorch+HF GPU image, modal.Volume for HF cache, and a generic run_experiment function that instantiates and runs any experiment on Modal GPUs, (4) core/data.py with WebDataset S3 streaming utilities — get_dataset() that takes a dataset config with S3 path and returns a streaming WebDataset pipeline with standard image transforms, (5) core/metrics.py with FID, latency, memory profiling utilities, (6) tasks/ with stub experiment classes for text_to_image, matting, segmentation, synthetic_data, vae, text_encoder — each extending base Experiment, (7) benchmarks/benchmark.py for latency/throughput/memory measurement, benchmarks/quantize.py for bitsandbytes int8/int4 and torch.compile wrappers, benchmarks/compare.py for Rich table model comparison, (8) utils/s3.py for S3 shard listing, utils/hf.py for HF Hub model loading helpers, utils/viz.py for image grid visualization, (9) scripts/run_experiment.py CLI entry point and scripts/benchmark.py CLI entry point, (10) configs/base.yaml template config, (11) README.md with project overview and usage.
Execution mode: sequential
Total tickets: 10

All tickets completed.
